#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
		This program is free software: you can redistribute it and/or modify
    it under the terms of the GNU General Public License as published by
    the Free Software Foundation, either version 3 of the License, or
    any later version.

    This program is distributed in the hope that it will be useful,
    but WITHOUT ANY WARRANTY; without even the implied warranty of
    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
    GNU General Public License for more details.

    You should have received a copy of the GNU General Public License
    along with this program.  If not, see <http://www.gnu.org/licenses/>.
"""

import os
import sys
import time
import pynotify
import ConfigParser

from xml.dom import minidom
from optparse import OptionParser
from collections import OrderedDict

class MultiOrderedDict(OrderedDict):
	def __setitem__(self, key, value):
		if isinstance(value, list) and key in self:
			self[key].extend(value)
		else:
			super(OrderedDict, self).__setitem__(key, value)

rsync_options = ""
backup_files = []
target = ""
pipeline = {}
postgres = []
pre_backup_script = ""
post_backup_script = ""
del_old_dumps=False
max_dumps = 10

def send_notification(message):
	"""send feed updates to notify-osd"""
	try:
		pynotify.init('Backup')
		n = pynotify.Notification('Backup', message, 'deja-dup')
		n.set_hint_string('x-canonical-append','')
		n.show()
	except:
		print message

def load_xml(path):
	global rsync_options
	global target
	global backup_files
	global pipeline
	global postgres
	global pre_backup_script
	global post_backup_script
	global del_old_dumps
	global max_dumps

	xmldoc = minidom.parse(path)
	optionlist = xmldoc.getElementsByTagName('options')
	for s in optionlist:
		for child in s.childNodes:
			if child.firstChild != None:
				if child.attributes['name'].value == 'rsync_options' and child.firstChild != None:
					rsync_options = child.firstChild.data
				elif child.attributes['name'].value == 'target' and child.firstChild != None:
					target = child.firstChild.data
				elif child.attributes['name'].value == 'pre_backup_script' and child.firstChild != None:
					pre_backup_script = child.firstChild.data
				elif child.attributes['name'].value == 'post_backup_script' and child.firstChild != None:
					post_backup_script = child.firstChild.data
				elif child.attributes['name'].value == 'max_dumps' and child.firstChild != None:
					max_dumps = int(child.firstChild.data)
				elif child.attributes['name'].value == 'delete_old_dumps' and child.firstChild != None:
					del_old_dumps = child.firstChild.data in ['true', 'True', 't', 'y', 'yes']

	backup_files_list = xmldoc.getElementsByTagName('backup_file')
	for s in backup_files_list:
		if s.firstChild != None:
			backup_file = {'source':s.firstChild.data.strip()}

			i = 0
			for child in s.childNodes:
				if child.nodeName == 'exclude':
					backup_file['exclude%d' % i] = child.firstChild.data.strip()
					i += 1
				elif child.nodeName == 'target':
					backup_file['target'] = child.firstChild.data.strip()
				elif child.nodeName == 'rsync_options':
					backup_file['rsync_options'] = child.firstChild.data.strip()
				elif child.nodeName == 'post_script':
					backup_file['post_script'] = child.firstChild.data.strip()

			backup_files.append(backup_file)

	pipelinelist = xmldoc.getElementsByTagName('pipe')
	for s in pipelinelist:
		pipeline[int(s.attributes['name'].value)] = s.firstChild.data

	postgreslist = xmldoc.getElementsByTagName('pgdb')
	for s in postgreslist:
		pgdb = {}
		for child in s.childNodes:
			if child.nodeName == 'name':
				pgdb['name'] = child.firstChild.data
			elif child.nodeName == 'user':
				pgdb['user'] = child.firstChild.data
			elif child.nodeName == 'password':
				pgdb['password'] = child.firstChild.data if child.firstChild != None else ''
			elif child.nodeName == 'target':
				pgdb['target'] = child.firstChild.data
			elif child.nodeName == 'options':
				pgdb['options'] = child.firstChild.data

		postgres.append(pgdb)

	if not target:
		print "No target provided."
		sys.exit(1)

	if len(pipeline) == 0:
		pipeline[1] = "backup"

def load_properties(path):
	global rsync_options
	global target
	global backup_files
	global pipeline
	global postgres
	global pre_backup_script
	global post_backup_script
	global del_old_dumps
	global max_dumps

	config = ConfigParser.RawConfigParser(dict_type=MultiOrderedDict)
	config.read([path])

	if config.has_section('options'):
		if config.has_option('options', 'target'):
			target = config.get('options', 'target')[0]
		if config.has_option('options', 'rsync_options'):
			rsync_options = config.get('options', 'rsync_options')[0]
		if config.has_option('options', 'pre_backup_script'):
			pre_backup_script = config.get('options', 'pre_backup_script')[0]
		if config.has_option('options', 'post_backup_script'):
			post_backup_script = config.get('options', 'post_backup_script')[0]
		if config.has_option('options', 'delete_old_dumps'):
			del_old_dumps = config.get('options', 'delete_old_dumps')[0] in ['true', 'True', 't', 'y', 'yes']
		if config.has_option('options', 'max_dumps'):
			max_dumps = int(config.get('options', 'max_dumps')[0])

	i = 1
	while config.has_section('backup%d' % i):
		backup_file = {'source':config.get('backup%d' % i, 'source')[0]}

		if config.has_option('backup%d' % i, 'exclude'):
			excludes = (config.get('backup%d' % i, 'exclude'))
			j = 0
			for exclude in excludes:
				backup_file['exclude%d' % j] = exclude
				j += 1
		if config.has_option('backup%d' % i, 'target'):
			backup_file['target'] = config.get('backup%d' % i, 'target')[0]
		if config.has_option('backup%d' % i, 'rsync_options'):
			backup_file['rsync_options'] = config.get('backup%d' % i, 'rsync_options')[0]
		if config.has_option('backup%d' % i, 'post_script'):
			backup_file['post_script'] = config.get('backup%d' % i, 'post_script')[0]

		backup_files.append(backup_file)
		i += 1

	i = 1
	while config.has_section('pgdb%d' % i):
		pgdb = {}

		if config.has_option('pgdb%d' % i, 'name'):
			pgdb['name'] = config.get('pgdb%d' % i, 'name')[0]
		if config.has_option('pgdb%d' % i, 'user'):
			pgdb['user'] = config.get('pgdb%d' % i, 'user')[0]
		if config.has_option('pgdb%d' % i, 'password'):
			pgdb['password'] = config.get('pgdb%d' % i, 'password')[0]
		if config.has_option('pgdb%d' % i, 'options'):
			pgdb['options'] = config.get('pgdb%d' % i, 'options')[0]
		if config.has_option('pgdb%d' % i, 'target'):
			pgdb['target'] = config.get('pgdb%d' % i, 'target')[0]
		i += 1

	if config.has_section('pipeline'):
		i = 1
		while config.has_option('pipeline', str(i)):
			pipeline[i] = config.get('pipeline', str(i))[0]
			i += 1

	if not target:
		print "No target provided."
		sys.exit(1)

	if len(pipeline) == 0:
		pipeline[1] = "backup"


def backup():
	print "--------------------------------------------------"
	for files in backup_files:
		send_notification("Start backup of '%s'." % files['source'])
		print "Backup of: " + files['source']

		excludes = ''
		exclude = ''
		current_rsync_options = rsync_options
		current_target = target
		for key, value in files.iteritems():
			if key.startswith('exclude'):
				excludes += value + ", "
				exclude += " --exclude=" + value
			elif key == 'rsync_options':
				current_rsync_options = value
			elif key == 'target':
				current_target = value

		if len(excludes) > 0:
			print "Exclude: " + excludes[0:len(excludes) - 2]

		folder = files['source'][files['source'].index(':') + 1:] if files['source'].startswith('ssh ') else files['source']
		if os.path.isdir(folder) or files['source'].startswith('ssh '):
			if current_target == target:
				current_target += folder

			if not os.path.exists(os.path.dirname(current_target)):
				os.makedirs(os.path.dirname(current_target))

			os.system("rsync %s %s %s %s" % (exclude, current_rsync_options, files['source'] + '/', current_target))
		else:
			dirname = os.path.dirname(files['source'])
			if current_target == target:
				current_target += dirname

			if not os.path.exists(os.path.dirname(current_target)):
				os.makedirs(os.path.dirname(current_target))

			os.system("rsync %s %s %s" % (current_rsync_options, files['source'], current_target))

		if 'post_script' in files:
			send_notification("Start post script.")
			print "Start post script."
			os.system(files['post_script'])
	print "--------------------------------------------------"

def run_pre_backup_script():
	if not pre_backup_script:
		return

	print "--------------------------------------------------"
	os.system(pre_backup_script)
	print "--------------------------------------------------"

def run_post_backup_script():
	if not post_backup_script:
		return

	print "--------------------------------------------------"
	send_notification("Start post backup script.")
	os.system(post_backup_script)
	print "--------------------------------------------------"

def postgres_dump():
	global postgres
	global del_old_dumps

	print "--------------------------------------------------"
	print "Start backup of PostgreSQL databases."
	send_notification("Start backup of PostgreSQL databases.")

	timestamp = time.strftime("%Y-%m-%dT%H:%M:%S", time.localtime())
	for pgdb in postgres:
		os.system("PGPASSWORD=%s pg_dump --username=%s %s %s | gzip -c > %s" % (pgdb['password'], pgdb['user'], pgdb['options'], pgdb['name'], os.path.join(pgdb['target'], "%s_%s.sql.gz" % (pgdb['name'], timestamp))))

		if del_old_dumps:
			delete_old_dumps(pgdb['target'])
	print "--------------------------------------------------"

def delete_old_dumps(folder):
	global max_dumps

	if len([f for f in os.listdir(folder) if os.path.isfile(os.path.join(folder, f))]) > max_dumps:
		files = sorted([f for f in os.listdir(folder) if os.path.isfile(os.path.join(folder, f))], reverse=True)
		j = 1
		for i in xrange(len(files) - 1):
			if j >= max_dumps:
				os.remove(os.path.join(folder, files[i]))
				continue

			if os.system("zcmp -s %s %s" % (os.path.join(folder, files[i]), os.path.join(folder, files[i + 1]))) > 0:
				os.remove(os.path.join(folder, files[i]))
			else:
				j += 1

			if len([f for f in os.listdir(folder) if os.path.isfile(os.path.join(folder, f))]) <= max_dumps:
				break

def run():
	global pipeline

	usage = "usage: %prog [options]"
	parser = OptionParser(usage)
	parser.add_option('-x', '--xml', action='store', type='string', dest='xml')
	parser.add_option('-p', '--properties', action='store', type='string', dest='properties')
	parser.add_option("-n", "--no-postgres", action="store_true", dest="postgres", help="disables PostgreSQL dump")
	(options, args) = parser.parse_args()

	if options.xml != None:
		load_xml(options.xml)
	elif options.properties != None:
		load_properties(options.properties)
	else:
		parser.print_help()

	for k, v in sorted(pipeline.iteritems()):
		if v == 'backup':
			backup()
		elif v == 'postgres_dump' and not options.postgres:
			postgres_dump()
		elif v == 'pre_backup_script':
			run_pre_backup_script()
		elif v == 'post_backup_script':
			run_post_backup_script()

if __name__ == '__main__':
	run()