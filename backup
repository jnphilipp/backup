#!/usr/bin/env python3
# -*- coding: utf-8 -*-
# vim: ft=python fileencoding=utf-8 sts=4 sw=4 et:
# Copyright (C) 2019-2023 J. Nathanael Philipp (jnphilipp) <nathanael@philipp.land>
# backup: Easily configure and reproducibly run complex backups.
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
"""backup: Easily configure and reproducibly run complex backups."""

import gzip
import logging
import re
import shlex
import socket
import subprocess
import sys
import time

from argparse import (
    ArgumentDefaultsHelpFormatter,
    ArgumentParser,
    FileType,
    RawTextHelpFormatter,
)
from enum import Enum
from lxml import etree
from pathlib import Path
from tempfile import TemporaryDirectory
from time import sleep
from threading import Thread
from typing import Callable, Dict, List, Optional, Set, TextIO, Tuple, Union


__author__ = "J. Nathanael Philipp (jnphilipp)"
__copyright__ = "Copyright 2019-2023 J. Nathanael Philipp (jnphilipp)"
__email__ = "nathanael@philipp.land"
__license__ = "GPLv3"
__version__ = "0.5.0"
__github__ = "https://github.com/jnphilipp/backup"


VERSION = (
    f"%(prog)s v{__version__}\n{__copyright__}\n"
    + "License GPLv3+: GNU GPL version 3 or later <https://gnu.org/licenses/gpl.html>."
    + "\nThis is free software: you are free to change and redistribute it.\n"
    + "There is NO WARRANTY, to the extent permitted by law.\n\n"
    + f"Report bugs to {__github__}/issues."
    + f"\nWritten by {__author__} <{__email__}>"
)
NAMESPACE = {"p": "https://github.com/jnphilipp/backup/"}


class Tool(str, Enum):
    """Supported backup tools."""

    BORG = "borg"
    DUPLICITY = "duplicity"
    RSYNC = "rsync"
    TAR = "tar"


class ArgFormatter(ArgumentDefaultsHelpFormatter, RawTextHelpFormatter):
    """Combination of ArgumentDefaultsHelpFormatter and RawTextHelpFormatter."""

    pass


def thread_logging(
    writer: Callable[[str], None], read_size: int = -1
) -> Callable[[TextIO], None]:
    """Create logging function for use in threads.

    Args:
     * writer: function to write output to
     * read_size: optional, length of bytes/chars to read at once

    Returns:
     * function to give to threads
    """

    def log(stream: TextIO):
        while True:
            line = stream.readline(read_size)
            if line:
                writer(line.split("\r")[-1].rstrip() if read_size == -1 else line)
            else:
                break

    return log


def run_command(
    args: List[str],
    cwd: Optional[str] = None,
    env: Optional[Dict[str, str]] = None,
    stdout_handler: Optional[Callable[[TextIO], None]] = thread_logging(
        lambda s: logging.log(15, s)
    ),
    stderr_handler: Optional[Callable[[TextIO], None]] = thread_logging(
        lambda s: logging.error(s)
    ),
) -> int:
    """Run a command.

    Args:
     * args: command and arguments
     * cwd: optional, current working directory to run from
     * env: optional, environment variables
     * stdout_handler: optional, function to handle stdout, run in a separate thread
     * stderr_handler: optional, function to handle stderr, run in a separate thread

    Returns:
     * return code
    """
    pobj = subprocess.Popen(
        args,
        stdout=subprocess.PIPE if stdout_handler else None,
        stderr=subprocess.PIPE if stderr_handler else None,
        cwd=cwd,
        env=env,
        text=True,
    )

    t_stdout = Thread(target=stdout_handler, args=(pobj.stdout,))
    t_stderr = Thread(target=stderr_handler, args=(pobj.stderr,))

    t_stdout.start()
    t_stderr.start()

    while t_stdout.is_alive() and t_stderr.is_alive():
        pass
    pobj.wait()
    sleep(1)

    return pobj.returncode


def make_db_dump_function(
    e: etree.Element,
    target: Path,
    cwd: Optional[str],
    env: Optional[Dict[str, str]],
    dry_run: bool = False,
) -> Callable[[], None]:
    """Make a function to create a database dump.

    Args:
     * e: etree element, as basis for the database dump
     * cwd: optional, current working directory to run from
     * env: optional, environment variables
     * dry_run: perform a dry run where no changes are performed

    Returns:
     * function to make database dump
    """
    logging.debug(f"Parsing XML element {e} for database.")

    name = e.find("p:name", namespaces=NAMESPACE).text.strip()
    user = e.find("p:user", namespaces=NAMESPACE).text.strip()
    password = (
        e.find("p:password", namespaces=NAMESPACE).text.strip()
        if e.find("p:password", namespaces=NAMESPACE) is not None
        else None
    )
    options = (
        shlex.split(e.find("p:options", namespaces=NAMESPACE).text.strip())
        if e.find("p:options", namespaces=NAMESPACE) is not None
        else None
    )
    ssh = None
    ssh_args = []
    if e.find("p:ssh", namespaces=NAMESPACE) is not None:
        essh = e.find("p:ssh", namespaces=NAMESPACE)
        ssh = essh.text.strip()
        ssh_args = shlex.split(essh.attrib["args"]) if "args" in essh.attrib else []

    if ssh is None:
        args: List[str] = []
        target /= Path(socket.gethostname())
    else:
        args = ["ssh", ssh] + ssh_args
        target /= Path(ssh)
    target /= Path("db-dumps")

    if etree.QName(e.getparent()).localname == "postgresql":
        db_name = "PostgreSQL"
        if ssh is not None:
            args += [f"PGPASSWORD={password}"]
        else:
            if env is None:
                env = {"PGPASSWORD": password}
            else:
                env["PGPASSWORD"] = password
        args += ["pg_dump", f"--username={user}"]
        target /= Path("PostgreSQL")
    elif etree.QName(e.getparent()).localname == "mysql":
        db_name = "MySQL"
        if ssh is not None:
            args += [f"MYSQL_PWD={password}"]
        else:
            if env is None:
                env = {"MYSQL_PWD": password}
            else:
                env["MYSQL_PWD"] = password
        args += ["mysqldump", f"--user={user}"]
        target /= Path("MySQL")
    else:
        raise RuntimeError("Unkown database.")

    if options is not None:
        args += options
    args.append(name)

    target /= Path(name)
    if not target.exists() and not dry_run:
        target.mkdir(parents=True, exist_ok=True)
    target /= f"{name}_{timestamp()}.sql.gz"

    logging.debug(
        f"{db_name}: name={name} user={user} password="
        f"{None if password is None else '*' * 5} options={options} ssh={ssh} "
        f"ssh-args={ssh_args} target={target}"
    )

    def dump():
        if ssh is not None:
            logging.info(f"Dumping remote {db_name} database {name} from {ssh}.")
        else:
            logging.info(f"Dumping {db_name} database {name}.")
        logging.debug(
            'Command: "'
            + '" "'.join(
                [re.sub("(MYSQL_PWD|PGPASSWORD)=(.+)", "\\1=*****", a) for a in args]
            )
            + '"'
        )
        logging.debug(
            'Env: "'
            + (
                "None"
                if env is None
                else '" "'.join(
                    [
                        f"{k}={'*****' if k in ['MYSQL_PWD', 'PGPASSWORD'] else v}"
                        for k, v in env.items()
                    ]
                )
            )
            + '"'
        )
        logging.debug(f"Cwd: {cwd}")

        if not dry_run:
            with gzip.open(target, "wt", encoding="utf8") as f:
                if (
                    run_command(
                        args,
                        cwd,
                        env,
                        thread_logging(lambda s: f.write(s)),
                        thread_logging(lambda s: logging.error(s)),
                    )
                    != 0
                ):
                    if ssh is not None:
                        logging.error(
                            f"Remote {db_name} dump of {name} from {ssh} failed."
                        )
                    else:
                        logging.error(f"{db_name} dump of {name} failed.")
                else:
                    logging.debug("Database dump successful.")

    return dump


def make_source_backup_function(
    elem: etree.Element,
    target: Path,
    tool_args: Tuple[Tool, List[str]],
    cwd: Optional[str],
    env: Optional[Dict[str, str]],
    dry_run: bool = False,
    scripts: Dict[int, List[str]] = {},
) -> Callable[[], None]:
    """Make a function to create a backup of a source.

    Args:
     * e: etree element, as basis for the backup
     * target: target for the backup
     * tool_args: backup tool to use and arguments
     * cwd: optional, current working directory to run from
     * env: optional, environment variables
     * dry_run: perform a dry run where no changes are performed
     * scripts: pre- and post-backup scripts

    Returns:
     * function to make a backup
    """
    logging.debug(f"Parsing XML element {elem} for database.")
    tool, args = tool_args[0], [tool_args[0].value] + tool_args[1].copy()

    path = Path(elem.find("p:path", namespaces=NAMESPACE).text.strip())

    ssh = None
    sshfs = None
    sshfs_args = []
    if "sshfs" in elem.attrib:
        sshfs = elem.attrib["sshfs"]
        if "sshfs-args" in elem.attrib:
            sshfs_args = shlex.split(elem.attrib["sshfs-args"])
        target /= Path(elem.attrib["sshfs"])
    elif "ssh" in elem.attrib:
        ssh = elem.attrib["ssh"]
        target /= Path(elem.attrib["ssh"])
    else:
        target /= Path(socket.gethostname())
    backup_dir = target / Path("backup")
    backup_dir /= path.relative_to(backup_dir.anchor)
    target /= Path("files") / path.relative_to(target.anchor)
    snapshot = target / f"{path.name}.snapshot"
    tar_name = f"{path.name}.%d.tar"
    if not target.exists() and not dry_run:
        target.mkdir(parents=True, exist_ok=True)
        if tool == Tool.BORG:
            logging.warning(
                f"No borg repository found in {target.absolute()}, initializing it."
            )
            run_command(
                ["borg", "init", "--encryption", "repokey", str(target.absolute())],
                cwd,
                env,
                None,
                None,
            )

    for i in range(len(args)):
        if tool == Tool.TAR:
            if args[i] in ["-z", "--gzip", "--gunzip", "--ungzip"]:
                tar_name += ".gz"
            elif args[i] in ["-j", "--bzip2"]:
                tar_name += ".bz2"
            elif args[i] in ["-J", "--xz"]:
                tar_name += ".xz"
            elif args[i] == "--lzip":
                tar_name += ".lz"
            elif args[i] == "--lzma":
                tar_name += ".lzma"
            elif args[i] == "--lzop":
                tar_name += ".lzo"
            elif args[i] in ["-Z", "--compress", "--uncompress"]:
                tar_name += ".Z"
            elif args[i] == "--zstd":
                tar_name += ".zst"
            elif args[i] == "--listed-incremental=%s":
                tar_name %= len(list(target.glob(tar_name.replace("%d", "*"))))
                args[i] %= snapshot
        if args[i] == "--backup-dir=%s":
            args[i] %= backup_dir
    for e in elem.xpath("p:exclude|p:include|p:pattern", namespaces=NAMESPACE):
        args.append(f"--{etree.QName(e).localname}={e.text.strip()}")

    pre_script = (
        scripts[int(elem.find("p:pre_script", namespaces=NAMESPACE).text.strip())]
        if elem.find("p:pre_script", namespaces=NAMESPACE) is not None
        else None
    )
    post_script = (
        scripts[int(elem.find("p:post_script", namespaces=NAMESPACE).text.strip())]
        if elem.find("p:post_script", namespaces=NAMESPACE) is not None
        else None
    )

    if tool == Tool.BORG:
        if sshfs is not None:
            if path.name == "":
                backup_name = f"{elem.attrib['sshfs']}-{{now}}"
            else:
                backup_name = f"{elem.attrib['sshfs']}:{path.name}-{{now}}"
            args += [f"{target.absolute()}::{backup_name}", "."]
        else:
            if path.name == "":
                backup_name = "{hostname}-{now}"
            else:
                backup_name = f"{{hostname}}:{path.name}-{{now}}"
            args += [f"{target.absolute()}::{backup_name}", str(path)]
        args = [args[0], "create"] + args[1:]
    elif tool == Tool.DUPLICITY:
        if "sshfs" in elem.attrib:
            args += [".", f"file://{target.absolute()}"]
        elif "ssh" in elem.attrib:
            args += [f"{elem.attrib['ssh']}:{path}", f"file://{target.absolute()}"]
        else:
            args += [str(path), f"file://{target.absolute()}"]
    elif tool == Tool.RSYNC:
        if "sshfs" in elem.attrib:
            args += [".", str(target.absolute())]
        elif "ssh" in elem.attrib:
            args += [f"{elem.attrib['ssh']}:{path}/", str(target.absolute())]
        else:
            args += [f"{path}/", str(target.absolute())]
    elif tool == Tool.TAR:
        if "sshfs" in elem.attrib:
            args += ["--file", str((target / tar_name).absolute()), "."]
        else:
            args += ["--file", str((target / tar_name).absolute()), str(path)]

    def backup():
        if ssh is not None:
            logging.info(f"Backing up source {path} from {ssh}.")
        elif sshfs is not None:
            logging.info(f"Backing up source {path} mounted from {sshfs}.")
        else:
            logging.info(f"Backing up source {path}.")
        logging.debug('Command: "' + '" "'.join(args) + '"')
        logging.debug(
            'Env: "'
            + (
                "None"
                if env is None
                else '" "'.join([f"{k}={v}" for k, v in env.items()])
            )
            + '"'
        )
        logging.debug(f"Cwd: {'TEMPDIR' if sshfs else cwd}")

        if dry_run:
            return

        tmpdir = None
        if sshfs is not None:
            tmpdir = TemporaryDirectory(prefix="backup-")
            logging.info(f"Mounting {sshfs}:{path} into {tmpdir.name}.")
            run_command(
                ["sshfs"] + sshfs_args + [f"{sshfs}:{path}", tmpdir.name],
                None,
                env,
            )
        if pre_script is not None:
            logging.info("Run pre script.")
            run_command(pre_script, tmpdir.name if sshfs else cwd, env)

        rc = run_command(
            args,
            tmpdir.name if sshfs else cwd,
            env,
            thread_logging(lambda s: logging.log(15, s)),
            thread_logging(
                lambda s: logging.log(15 if tool == Tool.BORG else logging.ERROR, s)
            ),
        )
        if tool == Tool.BORG and rc == 1:
            logging.warning(
                "There where some warnings during the backup, but it reached its "
                "normal end. You should check the logs."
            )
        elif rc != 0:
            if ssh is not None:
                logging.error(f"Backup of {path} from {ssh} failed.")
            elif sshfs is not None:
                logging.error(f"Backup of {path} mounted from {sshfs} failed.")
            else:
                logging.error(f"Backup of {path} failed.")
        else:
            logging.debug("Backup successful.")

        if post_script is not None:
            logging.info("Run post script.")
            run_command(post_script, tmpdir.name if sshfs else cwd, env)
        if tmpdir is not None:
            logging.info(f"Dismounting {tmpdir.name}.")
            run_command(["fusermount3", "-u", tmpdir.name], None, env)
            tmpdir.cleanup()

    return backup


def to_bool(string: str, default: bool = False) -> bool:
    """Convert string to bool.

    Args:
     * string: string to convert
     * default: default boolean if no match

    Returns:
     * boolean value
    """
    if string == "1" or string == "yes" or string == "true" or string == "on":
        return True
    elif string == "0" or string == "no" or string == "false" or string == "off":
        return False
    else:
        return default


def timestamp() -> str:
    """Get current timestamp as string.

    Returns:
     * current timestamp in the format of "%Y%m%dT%H%M%S"
    """
    return time.strftime("%Y%m%dT%H%M%S", time.localtime())


def load(
    path: Union[Path, TextIO], schema_path: str = "/usr/share/backup/backup.xsd"
) -> Optional[etree.ElementTree]:
    """Load XML and check validity.

    Args:
     * path: path to XML file
     * schema_path: path to XSD schema

    Returns:
     * XML as etree.ElementTree if valid otherwise None
    """
    if not Path(schema_path).exists():
        schema_path = "./backup.xsd"
    logging.debug(
        f'Loading XML file "{path if isinstance(path, Path) else path.name}".'
    )
    doc = etree.parse(str(path.absolute()) if isinstance(path, Path) else path)

    logging.debug(f'Loading XML schema "{schema_path}".')
    xmlschema = etree.XMLSchema(etree.parse(schema_path))

    if not xmlschema.validate(doc):
        logging.critical(
            f"XML file {path if isinstance(path, Path) else path.name} is not valid."
        )
        logging.critical(xmlschema.error_log.last_error)
        return None
    elif doc.xpath("//p:source[@ssh and @sshfs]", namespaces=NAMESPACE):
        logging.critical(
            f"XML file {path if isinstance(path, Path) else path.name} is not valid."
        )
        logging.critical(
            "Currently it is only supported that a source element has either the "
            "attribute ssh or sshfs."
        )
        return None
    elif doc.xpath("//p:tool[@name = 'borg'] and //p:include", namespaces=NAMESPACE):
        logging.critical(
            f"XML file {path if isinstance(path, Path) else path.name} is not valid."
        )
        logging.critical("Borg does not support include, use pattern.")
        return None
    elif doc.xpath(
        "not(//p:tool[@name = 'borg']) and //p:pattern", namespaces=NAMESPACE
    ):
        logging.critical(
            f"XML file {path if isinstance(path, Path) else path.name} is not valid."
        )
        logging.critical("The pattern-tag can only be used with borg.")
        return None
    elif doc.xpath(
        "//p:tool[@name = 'borg'] and //p:source[@ssh]", namespaces=NAMESPACE
    ):
        logging.critical(
            f"XML file {path if isinstance(path, Path) else path.name} is not valid."
        )
        logging.critical("Currently borg with ssh is not supported.")
        return None
    elif doc.xpath(
        "//p:tool[@name = 'tar'] and //p:source[@ssh]", namespaces=NAMESPACE
    ):
        logging.critical(
            f"XML file {path if isinstance(path, Path) else path.name} is not valid."
        )
        logging.critical("Currently ssh with tar is not supported.")
        return None
    else:
        logging.debug(
            f"XML file {path if isinstance(path, Path) else path.name} is valid."
        )
        return doc


def parse(
    path: Union[Path, TextIO],
    target: Optional[Path] = None,
    tool: Optional[Tuple[Tool, List[str]]] = None,
    dry_run: bool = False,
) -> Tuple[
    Dict[int, str],
    List[Callable[[], None]],
    List[Callable[[], None]],
    List[Callable[[], None]],
    Dict[int, List[str]],
]:
    """Parse XML file.

    Args:
     * path: path to XML file to parse
     * target: optional target to use as default target
     * tool: tuple of backup tool and it's arguments
     * dry_run: perform a dry run where no changes are performed
    """
    doc = load(path)
    if doc is None:
        sys.exit(1)

    if tool is None:
        e = doc.find("p:tool", namespaces=NAMESPACE)
        tool = (
            Tool(e.attrib["name"].strip()),
            shlex.split(e.text.strip()) if e.text else [],
        )

    if target is None and doc.find("p:target", namespaces=NAMESPACE) is not None:
        target = Path(doc.find("p:target", namespaces=NAMESPACE).text.strip())
    if target is None:
        logging.error("No target provided.")
        sys.exit(1)

    mysqls: List[Callable[[], None]] = []
    for e in doc.xpath("p:databases/p:mysql/*", namespaces=NAMESPACE):
        mysqls.append(make_db_dump_function(e, target, None, None, dry_run))

    pgsqls: List[Callable[[], None]] = []
    for e in doc.xpath("p:databases/p:postgresql/*", namespaces=NAMESPACE):
        pgsqls.append(make_db_dump_function(e, target, None, None, dry_run))

    scripts: Dict[int, List[str]] = {}
    for e in doc.xpath("p:scripts/p:script", namespaces=NAMESPACE):
        scripts[int(e.attrib["id"].strip())] = shlex.split(e.text.strip())

    sources: List[Callable[[], None]] = []
    for e in doc.xpath("p:sources/p:source", namespaces=NAMESPACE):
        sources.append(
            make_source_backup_function(e, target, tool, None, None, dry_run, scripts)
        )

    pipeline: Dict[int, str] = {}
    for step in doc.xpath("p:pipeline/*", namespaces=NAMESPACE):
        pipeline[int(step.attrib["no"].strip())] = step.text.strip()

    for e in doc.xpath("p:sources/p:file", namespaces=NAMESPACE) + doc.xpath(
        "p:databases/p:file", namespaces=NAMESPACE
    ):
        npath = Path(e.text.strip())
        if not npath.is_absolute():
            if isinstance(path, Path):
                npath = path.parent / npath
            else:
                npath = Path(path.name).parent / npath
        values = parse(npath, target, tool, dry_run)
        sources += values[1]
        mysqls += values[2]
        pgsqls += values[3]

    return pipeline, sources, mysqls, pgsqls, scripts


def snapshot(sources: List):
    """Make a snapshot of a list of Sources and stores it in a tar.gz.

    Args:
     * sources: list of sources to include in the snapshot
    """
    base_dirs: Set[Path] = set()
    for source in sources:
        base_dirs.add(source.target / source.hostname)

    for base_dir in base_dirs:
        logging.info(f"Taking snapshot of: {base_dir}")

        snapshot_dir = base_dir / "snapshots"
        if not snapshot_dir.exists():
            snapshot_dir.mkdir(parents=True, exist_ok=True)
        snapshot_dir /= f"{timestamp()}.tar.gz"
        files_dir = base_dir / "files"
        run_command(
            ["tar", "-czf", str(snapshot_dir)]
            + [file.name for file in files_dir.iterdir()],
            str(files_dir),
        )


def filter_info(rec: logging.LogRecord) -> bool:
    """Log record filter for info and lower levels.

    Args:
     * rec: LogRecord object
    """
    return rec.levelno <= logging.INFO


if __name__ == "__main__":
    parser = ArgumentParser(prog="backup", formatter_class=ArgFormatter)
    parser.add_argument(
        "-V",
        "--version",
        action="version",
        version=VERSION,
    )
    parser.add_argument(
        "--is-valid",
        action="store_true",
        dest="check_valid",
        help="checks the given XML file validity.",
    )
    parser.add_argument(
        "-d",
        "--no-database",
        action="store_true",
        dest="database",
        help="disable database dumps.",
    )
    parser.add_argument(
        "-p",
        "--no-postgres",
        action="store_true",
        dest="postgres",
        help="disables PostgreSQL dumps.",
    )
    parser.add_argument(
        "-m",
        "--no-mysql",
        action="store_true",
        dest="mysql",
        help="disables MySQL dumps.",
    )
    parser.add_argument(
        "-s",
        "--snapshot",
        action="store_true",
        dest="snapshot",
        help="make a snapshot, as tar.gz.",
    )
    parser.add_argument(
        "-S",
        "--snapshot-only",
        action="store_true",
        dest="snapshot_only",
        help="only make a snapshot, as tar.gz.",
    )
    parser.add_argument(
        "-v",
        "--verbose",
        action="count",
        default=0,
        help="verbosity level; multiple times increases the level, the maximum is 3, "
        + "for debugging.",
    )
    parser.add_argument(
        "-f",
        "--log-format",
        default="%(message)s",
        help="set logging format.",
    )
    parser.add_argument(
        "--log-file",
        type=lambda p: Path(p).absolute(),
        help="log output to a file.",
    )
    parser.add_argument(
        "--log-file-format",
        default="[%(levelname)s] %(message)s",
        help="set logging format for log file.",
    )
    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="do a dry run with perfomring no changes.",
    )
    parser.add_argument(
        "XML",
        type=FileType("r", encoding="utf8"),
        default=sys.stdout,
        help="XML config file.",
    )
    parser.add_argument(
        "TARGET",
        nargs="?",
        type=lambda p: Path(p).absolute(),
        help="optional backup target, will override target defined in XML config.",
    )
    args = parser.parse_args()

    logging.addLevelName(15, "STDOUT")
    if args.verbose == 0:
        level = logging.WARNING
    elif args.verbose == 1:
        level = logging.INFO
    elif args.verbose == 2:
        level = 15
    else:
        level = logging.DEBUG

    handlers: List[logging.Handler] = []
    stdout_handler = logging.StreamHandler(sys.stdout)
    stdout_handler.setLevel(level)
    stdout_handler.addFilter(filter_info)
    handlers.append(stdout_handler)

    stderr_handler = logging.StreamHandler(sys.stderr)
    stderr_handler.setLevel(logging.WARNING)
    if "%(levelname)s" not in args.log_format:
        stderr_handler.setFormatter(
            logging.Formatter(f"[%(levelname)s] {args.log_format}")
        )
    handlers.append(stderr_handler)

    if args.log_file:
        file_handler = logging.FileHandler(args.log_file)
        file_handler.setLevel(15)
        if args.log_file_format:
            file_handler.setFormatter(logging.Formatter(args.log_file_format))
        handlers.append(file_handler)

    logging.basicConfig(
        format=args.log_format,
        level=logging.DEBUG,
        handlers=handlers,
    )

    if args.dry_run:
        logging.warning("Performing dry run, no changes will be done.")

    pipeline: Dict[int, str] = {}
    if args.XML is not None:
        if args.check_valid:
            if load(args.XML) is not None:
                logging.info(f"XML file {args.XML.name} is valid.")
                sys.exit(0)
            else:
                sys.exit(1)
        else:
            if args.TARGET:
                logging.info(f"Using '{args.TARGET}' as backup target.")
                if not args.TARGET.exists():
                    logging.log(
                        logging.WARN if args.dry_run else logging.CRITICAL,
                        "The given target path does not exists.",
                    )
                    if not args.dry_run:
                        sys.exit(1)

            pipeline, sources, mysqls, pgsqls, scripts = parse(
                args.XML, args.TARGET, dry_run=args.dry_run
            )
    else:
        parser.print_usage()

    if not args.snapshot_only:
        for k, v in sorted(pipeline.items(), key=lambda x: x[0]):
            if v == "backup":
                for source in sources:
                    source()
            elif v == "postgresql-dbs" and not (args.postgres or args.database):
                for pgsql in pgsqls:
                    pgsql()
            elif v == "mysql-dbs" and not (args.mysql or args.database):
                for mysql in mysqls:
                    mysql()
            elif v.startswith("script-"):
                logging.info(f"Running script {scripts[int(v[7:])].path}.")
                if not args.dry_run:
                    run_command(scripts[int(v[7:])])

    if args.snapshot or args.snapshot_only:
        snapshot(sources)

    if args.dry_run:
        logging.info("Dry run done.")
    else:
        logging.info("Backup done.")
